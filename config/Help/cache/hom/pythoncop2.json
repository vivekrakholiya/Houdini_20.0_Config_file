{"type": "root", "attrs": {}, "body": [{"level": 0, "type": "title", "indent": 0, "text": ["Define a compositing node (COP) using Python"], "extent": [0, 49]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 0, "text": ["How to"], "extent": [49, 63], "body": [{"type": "ord_group", "body": [{"blevel": 2, "type": "ord", "indent": 0, "text": ["Choose ", {"type": "ui", "text": ["File \u25b8 New Asset"]}, "."], "extent": [63, 96]}, {"blevel": 2, "type": "ord", "indent": 0, "text": ["Set ", {"type": "ui", "text": ["Definition"]}, " to ", {"type": "code", "text": ["Python"]}, ", then set ", {"type": "ui", "text": ["Network type"]}, " to ", {"type": "ui", "text": ["Compositing Filter"]}, " or ", {"type": "ui", "text": ["Compositing Generator"]}, "."], "extent": [96, 213]}, {"blevel": 2, "type": "ord", "indent": 0, "text": ["Use the ", {"type": "ui", "text": ["Save to library"]}, " option to set an OTL library file to save the new node type into."], "extent": [213, 310]}, {"blevel": 2, "type": "ord", "indent": 0, "text": ["Click ", {"type": "ui", "text": ["Accept"]}, "."], "extent": [310, 331], "body": [{"type": "para", "indent": 4, "text": ["The ", {"scheme": null, "value": "/ref/windows/optype", "type": "link", "text": ["type properties window"], "fullpath": "/ref/windows/optype.html"}, " appears."], "extent": [331, 394]}], "container": true}, {"blevel": 2, "type": "ord", "indent": 0, "text": ["Use the ", {"scheme": null, "value": "/ref/windows/optype", "type": "link", "text": ["options in the type properties window"], "fullpath": "/ref/windows/optype.html"}, " to define the interface for your new node type."], "extent": [394, 513]}, {"blevel": 2, "type": "ord", "indent": 0, "text": ["Click the ", {"type": "ui", "text": ["Code"]}, " tab to view and edit the Python code that defines the COP\u2019s behavior."], "extent": [513, 605]}], "container": true}, {"type": "tip_group", "body": [{"type": "tip", "indent": 0, "role": "item", "extent": [605, 610], "body": [{"type": "para", "indent": 4, "text": ["If you need to edit the code after closing the type properties window,\n    right-click an instance of the node and choose ", {"type": "ui", "text": ["Type properties"]}, "."], "extent": [610, 758]}], "container": true}], "container": true, "role": "item_group"}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 0, "text": ["Writing COP Filters"], "extent": [758, 784], "body": [{"type": "para", "indent": 0, "text": ["A Python COP filter produces new image data based on image data from one or\nmore input nodes.  Each node in COPs stores a number of image planes, and\neach plane is cooked separately.  Every COP has a ", {"type": "code", "text": ["C"]}, " (color) and an ", {"type": "code", "text": ["A"]}, "\n(alpha) plane, but a cop may create more planes.  Image planes in COPs are\ncooked on demand, so some planes may not cook unless the viewer or an output\nCOP asks for those planes."], "extent": [784, 1188]}, {"type": "para", "indent": 0, "text": ["Writing a COP node type using Python is different than writing, say, a SOP or\nObject node type in Python.  While Python SOPs and Objects evaluate the Python\ncode in the ", {"type": "ui", "text": ["Code"]}, " tab whenever the node cooks, Python COPs instead call\nspecially-named functions defined in the ", {"type": "ui", "text": ["Code"]}, " tab."], "extent": [1188, 1476]}, {"type": "para", "indent": 0, "text": ["When writing a Python COP filter, provide definitions of the following\nfunctions in the ", {"type": "ui", "text": ["Code"]}, " tab:"], "extent": [1476, 1579]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 0, "text": [{"type": "code", "text": ["output_planes_to_cook(cop_node)"]}], "extent": [1579, 1614], "body": [{"type": "para", "indent": 4, "text": ["This function is required.  It must return a sequence of strings containing\n    the names of the image planes that this COP cooks."], "extent": [1614, 1750]}, {"type": "para", "indent": 4, "text": ["Planes that are not listed in the result but are present in the first\n    input COP node will be passed through unmodified.  All COPs have both\n    ", {"type": "code", "text": ["C"]}, " and ", {"type": "code", "text": ["A"]}, " planes, so if one or both of these planes are not listed in\n    the result they will be passed through from the first input."], "extent": [1750, 2040]}, {"type": "para", "indent": 4, "text": ["Planes that are listed in the result but are not in the input node will\n    be created.  Note that these special planes will not cook until they are\n    needed, such as when they are displayed in the viewer."], "extent": [2040, 2253]}], "container": true}, {"type": "dt", "indent": 0, "text": [{"type": "code", "text": ["required_input_planes(cop_node, output_plane)"]}], "extent": [2253, 2302], "body": [{"type": "para", "indent": 4, "text": ["This function is required for COP filters.  It must return a sequence of\n    strings identifying the input numbers and the plane names required in order\n    for this node to cook.  The return sequence must have an even number of\n    strings, with the even elements containing the input numbers and the odd\n    elements containing the plane names."], "extent": [2302, 2654]}, {"type": "para", "indent": 4, "text": ["For example, this function could return ", {"type": "code", "text": ["(\"0\", \"C\", \"0\", \"A\", \"1\", \"C\")"]}, "\n    to indicate that planes ", {"type": "code", "text": ["C"]}, " and ", {"type": "code", "text": ["A"]}, " are required from the first input\n    and plane ", {"type": "code", "text": ["C"]}, " is needed from the second input."], "extent": [2654, 2857]}], "container": true}, {"type": "dt", "indent": 0, "text": [{"type": "code", "text": ["cook(cop_node, plane, resolution)"]}], "extent": [2857, 2894], "body": [{"type": "para", "indent": 4, "text": ["This function is required.  It is called multiple times, once for each\n    plane cooked by this node."], "extent": [2894, 3001]}, {"type": "para", "indent": 4, "text": [{"type": "code", "text": ["plane"]}, " is the name of the plane being cooked.  ", {"type": "code", "text": ["resolution"]}, " is a sequence\n    of two integers specifying the resolution of the planes in this node."], "extent": [3001, 3155]}, {"type": "para", "indent": 4, "text": ["To get the contents of a plane in an input node, call\n    ", {"scheme": "Hom", "value": "/hom/hou/Cop2Node#allPixels", "type": "link", "text": "", "fallback_text": "hou.Cop2Node.allPixels", "fullpath": "/hom/hou/Cop2Node.html#allPixels", "fragment": "#allPixels"}, " or ", {"scheme": "Hom", "value": "/hom/hou/Cop2Node#allPixelsAsString", "type": "link", "text": "", "fallback_text": "hou.Cop2Node.allPixelsAsString", "fullpath": "/hom/hou/Cop2Node.html#allPixelsAsString", "fragment": "#allPixelsAsString"}, ".  The\n    former returns a sequence of floats, while the latter is faster and\n    returns a binary string containing the image data in the requested format."], "extent": [3155, 3444]}, {"type": "para", "indent": 4, "text": ["If you call ", {"type": "code", "text": ["allPixels"]}, " or ", {"type": "code", "text": ["allPixelsAsString"]}, " on an input and plane that\n    was not returned by your ", {"type": "code", "text": ["required_input_planes"]}, " function, Houdini will\n    raise a ", {"scheme": "Hom", "value": "/hom/hou/OperationFailed", "type": "link", "text": "", "fallback_text": "hou.OperationFailed", "fullpath": "/hom/hou/OperationFailed.html"}, " exception."], "extent": [3444, 3648]}, {"type": "para", "indent": 4, "text": ["After computing the pixel data for the plane, call\n    ", {"scheme": "Hom", "value": "/hom/hou/Cop2Node#setPixelsOfCookingPlane", "type": "link", "text": "", "fallback_text": "hou.Cop2Node.setPixelsOfCookingPlane", "fullpath": "/hom/hou/Cop2Node.html#setPixelsOfCookingPlane", "fragment": "#setPixelsOfCookingPlane"}, " or\n    ", {"scheme": "Hom", "value": "/hom/hou/Cop2Node#setPixelsOfCookingPlaneFromString", "type": "link", "text": "", "fallback_text": "hou.Cop2Node.setPixelsOfCookingPlaneFromString", "fullpath": "/hom/hou/Cop2Node.html#setPixelsOfCookingPlaneFromString", "fragment": "#setPixelsOfCookingPlaneFromString"}, "."], "extent": [3648, 3812]}], "container": true}, {"type": "dt", "indent": 0, "text": [{"type": "code", "text": ["resolution(cop_node)"]}], "extent": [3812, 3836], "body": [{"type": "para", "indent": 4, "text": ["You only need to implement this function if your COP changes the image\n    resolution.  By default, your COP will use the resolution of its first\n    input."], "extent": [3836, 3998]}, {"type": "para", "indent": 4, "text": ["This function must return a sequence of two integers for the width and\n    height of the image.  Note that the resolution of the image cannot vary\n    with time.  COPs requires that all frames in an image sequence have the\n    same resolution."], "extent": [3998, 4247]}], "container": true}, {"type": "dt", "indent": 0, "text": [{"type": "code", "text": ["depth(cop_node, plane)"]}], "extent": [4247, 4273], "body": [{"type": "para", "indent": 4, "text": ["You only need to implement this function if you want to change the image\n    depth of an existing plane or you want the depth of a new plane to be\n    something other than 32-bit float.  By default, your COP will not change\n    plane depths and any planes it creates will be 32-bit float."], "extent": [4273, 4567]}, {"type": "para", "indent": 4, "text": ["This function must return a ", {"scheme": "Hom", "value": "/hom/hou/imageDepth", "type": "link", "text": "", "fallback_text": "hou.imageDepth", "fullpath": "/hom/hou/imageDepth.html"}, " enumerated value to\n    indicate the depth for the given plane to cook."], "extent": [4567, 4693]}], "container": true}, {"type": "dt", "indent": 0, "text": [{"type": "code", "text": ["frame_range(cop_node)"]}], "extent": [4693, 4718], "body": [{"type": "para", "indent": 4, "text": ["You only need to implement this function if your COP changes the frame\n    range information.  By default, your COP will use the frame range of its\n    first input."], "extent": [4718, 4888]}, {"type": "para", "indent": 4, "text": ["This function may return ", {"type": "code", "text": ["None"]}, " to indicate that it produces a still\n    image.  Otherwise, it must return a tuple of two integers indicating the\n    start frame and number of frames."], "extent": [4888, 5077]}], "container": true}, {"type": "dt", "indent": 0, "text": [{"type": "code", "text": ["remap_frame(cop_node, frame)"]}], "extent": [5077, 5109], "body": [{"type": "para", "indent": 4, "text": ["You only need to implement this function if your COP modifies timing\n    information.  Given a frame number in this node\u2019s frame range, this\n    function returns the corresponding frame number in the input node\u2019s frame\n    range.  This function lets you shift, scale, and warp the timing\n    information."], "extent": [5109, 5419]}, {"type": "para", "indent": 4, "text": ["If you implement this function, be sure to also implement ", {"type": "code", "text": ["frame_range"]}, "\n    to return the correct range."], "extent": [5419, 5529]}], "container": true}], "container": true}, {"type": "para", "indent": 0, "text": ["Notes:"], "extent": [5529, 5536]}, {"type": "bullet_group", "body": [{"blevel": 2, "type": "bullet", "indent": 0, "text": ["When calling ", {"type": "code", "text": ["allPixels\\[AsString\\]"]}, " or\n  ", {"type": "code", "text": ["setPixelsOfCookingPlane\\[FromString\\]"]}, ", scanlines are ordered with the\n  bottom scanline first."], "extent": [5536, 5677]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": ["You must pass in the correct data size to ", {"type": "code", "text": ["setPixelsOfCookingPlane*"]}, ", or\n  Houdini will raise a ", {"scheme": "Hom", "value": "/hom/hou/OperationFailed", "type": "link", "text": "", "fallback_text": "hou.OperationFailed", "fullpath": "/hom/hou/OperationFailed.html"}, " exception.  This function\n  can accept interleaved data or set the red, green, and blue components in\n  three separate calls.  See ", {"scheme": "Hom", "value": "/hom/hou/Cop2Node#setPixelsOfCookingPlane", "type": "link", "text": "", "fallback_text": "hou.Cop2Node.setPixelsOfCookingPlane", "fullpath": "/hom/hou/Cop2Node.html#setPixelsOfCookingPlane", "fragment": "#setPixelsOfCookingPlane"}, " for\n  more information."], "extent": [5677, 5999]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"type": "code", "text": ["allPixels"]}, " returns each component (e.g. red, green, blue, alpha, etc.) in\n  each pixel of the input image planes as a 32-bit float value, regardless of\n  the bit depth the input cop uses to store the data.  For example, if the\n  input cop stores the ", {"type": "q", "text": ["C"]}, " plane as an 8-bit unsigned value for the red\n  component, another 8-bit value for the green, and another for the blue,\n  asking for the ", {"type": "q", "text": ["C"]}, " plane of the input using ", {"type": "code", "text": ["allPixels"]}, " will return a 32-bit\n  float red component, a 32-bit float blue, and so on."], "extent": [5999, 6509]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"type": "code", "text": ["allPixelsAsString"]}, " can return each component in each pixel of an input image\n  plane in any of the image depths supported by the compositor: 8-bit integer,\n  16-bit integer, 32-bit integer, 16-bit float, or 32-bit float.  To request\n  a particular bit depth, set the depth parameter to a ", {"scheme": "Hom", "value": "/hom/hou/imageDepth", "type": "link", "text": "", "fallback_text": "hou.imageDepth", "fullpath": "/hom/hou/imageDepth.html"}, "\n  enumerated value.  If the depth parameter is not specified, the image depth\n  will be the same as the plane being cooked by the COP."], "extent": [6509, 6956]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": ["If your cop says that it cooks a plane by listing it in the return value\n  from ", {"type": "code", "text": ["output_planes_to_cook"]}, " but does not call ", {"type": "code", "text": ["setPixelsOfCookingPlane*"]}, "\n  from the ", {"type": "code", "text": ["cook"]}, " function, Houdini will fill all the pixels of the missing\n  component(s) with zeros."], "extent": [6956, 7210]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": ["Python COPs only allow you to get and set pixels in the frame, not in the\n  full canvas area.  In COPs, the frame is the visible region of the plane and\n  corresponds to the image\u2019s resolution.  However, a node can store additional\n  pixels outside the frame, and the region of all possible pixels is called the\n  canvas.  For example, if you use a transform cop to move the pixels off to\n  the right of the frame, then use another transform cop to move pixels back\n  left, the original pixels will appear in the frame.  The reason is that the\n  first transform cop\u2019s canvas extends beyond the frame, so it can cook the\n  pixels outside the frame when the second transform cop asks for them.\n  To make Python COPs simpler, their canvas is always the same size as the\n  frame, and they can only ask for input data that lies within the input\u2019s\n  frame."], "extent": [7210, 8063]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": ["You cannot access pixel data from a cop that is not an input to your node.\n  In other words, do not call ", {"type": "code", "text": ["allPixels*"]}, " on a COP node that is not an input\n  to your Python COP."], "extent": [8063, 8240]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": ["If your Python COP has multiple inputs and there may be gaps in the\n  connected inputs, use the ", {"scheme": "Hom", "value": "/hom/hou/Node#inputConnectors", "type": "link", "text": "", "fallback_text": "hou.Node.inputConnectors", "fullpath": "/hom/hou/Node.html#inputConnectors", "fragment": "#inputConnectors"}, " method.  For example,\n  if your COP has a maximum of 2 inputs but a minimum of 0, it is possible\n  for the first input to be disconnected and the second to be connected.  If\n  you call ", {"scheme": "Hom", "value": "/hom/hou/Node#inputs", "type": "link", "text": "", "fallback_text": "hou.Node.inputs", "fullpath": "/hom/hou/Node.html#inputs", "fragment": "#inputs"}, " it will return only one entry.  The following\n  code lets you access an input even when there are gaps:"], "extent": [8240, 8680], "body": [{"lang": "python", "type": "pre", "indent": 2, "text": ["\n  input_connections = cop_node.inputConnectors()[input_index]\n  if len(input_connections) == 0:\n      input_node = None\n  else:\n      input_node = input_connection[0].inputNode()\n  "], "extent": [8680, 8882]}], "container": true}], "container": true}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 0, "text": ["Writing COP Generators"], "extent": [8882, 8912], "body": [{"type": "para", "indent": 0, "text": ["The difference between a generator and a filter is simply the minimum number of\ninputs.  The same Python COP node type can act as both a filter and a\ngenerator.  For this section, a generator is simply a COP node without an\ninput and with a minimum number of inputs of zero."], "extent": [8912, 9189]}, {"type": "para", "indent": 0, "text": ["Python COP generators usually override the ", {"type": "code", "text": ["output_planes_to_cook"]}, ",\n", {"type": "code", "text": ["resolution"]}, ", ", {"type": "code", "text": ["depth"]}, ", and ", {"type": "code", "text": ["cook"]}, " methods."], "extent": [9189, 9301]}, {"type": "para", "indent": 0, "text": ["If Python COP generators do not override ", {"type": "code", "text": ["resolution"]}, ", the resolution will\nbe 1\u00d71.  If they do not override ", {"type": "code", "text": ["frame_range"]}, ", they will generate a still\nimage.  If they do not return the ", {"type": "q", "text": ["C"]}, " and ", {"type": "q", "text": ["A"]}, " planes from\n", {"type": "code", "text": ["output_planes_to_cook"]}, ", Houdini will still call ", {"type": "code", "text": ["cook"]}, " with those plane names."], "extent": [9301, 9590]}, {"type": "para", "indent": 0, "text": ["By default, planes created by Python COP generators are always 32-bit float.\nHowever, by providing a ", {"type": "code", "text": ["depth"]}, " function you can make them return any of the\nimage depths supported by the compositor."], "extent": [9590, 9787]}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 0, "text": ["Example COP Nodes"], "extent": [9787, 9811], "body": [{"type": "para", "indent": 0, "text": ["This Python COP generator produces a constant color and can take an optional\ninput.  When an input is connected, the resolution parameter is ignored and it\nuses the resolution of the input."], "extent": [9811, 10003]}, {"lang": "python", "type": "pre", "indent": 0, "text": ["\ndef output_planes_to_cook(cop_node):\n    return (\"C\", \"A\")\n\ndef required_input_planes(cop_node, output_plane):\n    return ()\n\ndef resolution(cop_node):\n    # If we don't have an input, use the value of the resolution parameter.\n    if len(cop_node.inputs()) == 0:\n        return cop_node.parmTuple(\"resolution\").eval()\n\n    # Use the resolution of the first connected input.\n    input = cop_node.inputs()[0]\n    return (input.xRes(), input.yRes())\n\ndef cook(cop_node, plane, resolution):\n    num_pixels = resolution[0] * resolution[1]\n    rgba = cop_node.parmTuple(\"color\").eval()\n    pixel = (rgba[3:] if plane == \"A\" else rgba[:3])\n    cop_node.setPixelsOfCookingPlane(pixel * num_pixels)\n"], "extent": [10003, 10711]}, {"type": "para", "indent": 0, "text": ["The following Python COP filter does not process any image data, but instead\nshifts the input sequence by the specified number of frames and then stretches\nthe timing by the specified scale factor.  It assumes the node has the\nfollowing parameters:"], "extent": [10711, 10962]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 0, "text": ["frameshift"], "extent": [10962, 10974], "body": [{"type": "para", "indent": 4, "text": ["the number of frames to shift the input sequence"], "extent": [10974, 11027]}], "container": true}, {"type": "dt", "indent": 0, "text": ["framescale"], "extent": [11027, 11039], "body": [{"type": "para", "indent": 4, "text": ["the scale factor to apply to the number of frames"], "extent": [11039, 11094]}], "container": true}], "container": true}, {"lang": "python", "type": "pre", "indent": 0, "text": ["\nimport math\n\ndef frame_range(cop_node):\n    input = cop_node.inputs()[0]\n    if input.isSingleImage():\n        return None\n\n    start_frame = int(input.sequenceStartFrame() + cop_node.evalParm(\"frameshift\"))\n    length_in_frames = int(math.floor(\n        input.sequenceFrameLength() * cop_node.evalParm(\"framescale\")))\n    return (start_frame, length_in_frames)\n\ndef remap_frame(cop_node, frame):\n    \"\"\"Return the frame number in the input required to cook the given frame\n    in this node.\n    \"\"\"\n    input = cop_node.inputs()[0]\n    input_start_frame = input.sequenceStartFrame()\n    frame_scale = cop_node.evalParm(\"framescale\")\n    frame_shift = cop_node.evalParm(\"frameshift\")\n\n    original_index_in_input = frame - input_start_frame\n    remapped_frame_in_input = ((original_index_in_input / frame_scale) +\n        input_start_frame - frame_shift)\n    return remapped_frame_in_input\n\ndef output_planes_to_cook(cop_node):\n    # By returning that no planes are cooked, they will be passed through\n    # from the input.\n    return ()\n\ndef cook(cop_node, plane, resolution):\n    pass\n"], "extent": [11094, 12198]}, {"type": "para", "indent": 0, "text": ["For a more complicated example that uses the\n", {"scheme": null, "value": "http://numpy.sourceforge.net", "type": "link", "text": ["numpy"], "exists": true}, " module (included with Houdini)\nto composite the same foreground\nimage in multiple locations over a background, see the\n", {"scheme": null, "value": "/hom/cb/pythoncop2", "type": "link", "text": ["Multi Stamp Python COP"], "fullpath": "/hom/cb/pythoncop2.html"}, " example from the\n", {"scheme": null, "value": "/hom/cb/", "type": "link", "text": ["HOM cookbook"], "fullpath": "/hom/cb/index.html"}, "."], "extent": [12198, 12487]}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 0, "text": ["Processing Pixel Data Efficiently"], "extent": [12487, 12527], "body": [{"type": "para", "indent": 0, "text": ["Python\u2019s overhead when constructing a list or tuple of many floats can be slow.\nSo, when possible, it is better to use ", {"scheme": "Hom", "value": "/hom/hou/Cop2Node#allPixelsAsString", "type": "link", "text": "", "fallback_text": "hou.Cop2Node.allPixelsAsString", "fullpath": "/hom/hou/Cop2Node.html#allPixelsAsString", "fragment": "#allPixelsAsString"}, "\ninstead of ", {"scheme": "Hom", "value": "/hom/hou/Cop2Node#allPixels", "type": "link", "text": "", "fallback_text": "hou.Cop2Node.allPixels", "fullpath": "/hom/hou/Cop2Node.html#allPixels", "fragment": "#allPixels"}, ". Using Python\u2019s\n", {"scheme": null, "value": "http://docs.python.org/library/array.html", "type": "link", "text": ["array"], "exists": true}, " module, you can efficiently\nconvert the string data into a sequence of 32-bit floats, as illustrated by the\nfollowing code:"], "extent": [12527, 12915]}, {"lang": "python", "type": "pre", "indent": 0, "text": ["\nimport array\nstr_data = input_cop_node.allPixelsAsString(\"C\")\nfloat_data = array.array(\"f\", str_data)\n"], "extent": [12915, 13034]}, {"type": "para", "indent": 0, "text": ["Similarly, it is more efficient to call\n", {"scheme": "Hom", "value": "/hom/hou/Cop2Node#setPixelsOfCookingPlaneFromString", "type": "link", "text": "", "fallback_text": "hou.Cop2Node.setPixelsOfCookingPlaneFromString", "fullpath": "/hom/hou/Cop2Node.html#setPixelsOfCookingPlaneFromString", "fragment": "#setPixelsOfCookingPlaneFromString"}, " instead of calling\n", {"scheme": "Hom", "value": "/hom/hou/Cop2Node#setPixelsOfCookingPlane", "type": "link", "text": "", "fallback_text": "hou.Cop2Node.setPixelsOfCookingPlane", "fullpath": "/hom/hou/Cop2Node.html#setPixelsOfCookingPlane", "fragment": "#setPixelsOfCookingPlane"}, " with a list or tuple of floats.\nWhile you could convert from an array into a string by calling\n", {"type": "code", "text": ["float_data.tostring()"]}, ", ", {"type": "code", "text": ["setPixelsOfCookingPlaneFromString"]}, " can accept\nthe array object directly:"], "extent": [13034, 13385]}, {"lang": "python", "type": "pre", "indent": 0, "text": ["\ncop_node.setPixelsOfCookingPlaneFromString(float_data)\n"], "extent": [13385, 13457]}, {"type": "para", "indent": 0, "text": ["Houdini includes the ", {"scheme": null, "value": "http://numpy.scipy.org/", "type": "link", "text": ["numpy"], "exists": true}, " library. You can\nuse it to reinterpret the contents of a binary string as a sequence of\n32-bit floats, without having to construct a new copy of the data:"], "extent": [13457, 13667]}, {"lang": "python", "type": "pre", "indent": 0, "text": ["\nimport numpy\nstr_data = input_cop_node.allPixelsAsString(\"C\")\nread_only_float_data = numpy.frombuffer(str_data, dtype=numpy.float32)\n"], "extent": [13667, 13817]}, {"type": "para", "indent": 0, "text": ["String data that has been reinterpreted as float data is read-only.  If you\nwant to make a copy of the data to modify it, though, simply call ", {"type": "code", "text": ["copy()"]}, "\non it:"], "extent": [13817, 13977]}, {"lang": "python", "type": "pre", "indent": 0, "text": ["\nwritable_float_data = read_only_float_data.copy()\n"], "extent": [13977, 14044]}, {"type": "para", "indent": 0, "text": ["To convert the numpy array into a string, you could write\n", {"type": "code", "text": ["str(writable_float_data.data)"]}, ".  However, you can pass the numpy array\ndirectly into ", {"type": "code", "text": ["setPixelsOfCookingPlaneFromString"]}, ":"], "extent": [14044, 14227]}, {"lang": "python", "type": "pre", "indent": 0, "text": ["\ncop_node.setPixelsOfCookingPlaneFromString(writable_float_data)\n"], "extent": [14227, 14308]}, {"type": "para", "indent": 0, "text": ["Processing one pixel at a time inside a Python loop can be slow. ", {"type": "code", "text": ["numpy"]}, "'s\narrays provide efficient ways to operate on multiple pixels without requiring\nPython\u2019s looping constructs.  The following example implements a node that\nbrightens the pixels in an image.  It assumes the COP has a float parameter\nnamed ", {"type": "code", "text": ["bright"]}, "."], "extent": [14308, 14630]}, {"lang": "python", "type": "pre", "indent": 0, "text": ["\nimport numpy\n\ndef output_planes_to_cook(cop_node):\n    return (\"C\",)\n\ndef required_input_planes(cop_node, output_plane):\n    if output_plane == \"C\":\n        return (\"0\", \"C\")\n    return ()\n\ndef cook(cop_node, plane, resolution):\n    input = cop_node.inputs()[0]\n    \n    if resolution != (input.xRes(), input.yRes()):\n        # Houdini may request to cook the COP node at resolutions other\n        # than the input node's resolution.  For example, Houdini may\n        # request a lower resolution for a preview image of the COP node data.\n        # We currently cannot create a preview image so do nothing and just\n        # return.\n        return\n\n    # Grab the pixels from the corresponding plane in the input, then build\n    # a numpy array from the data.\n    pixels = numpy.frombuffer(\n        input.allPixelsAsString(plane), dtype=numpy.float32).reshape(\n        resolution[1], resolution[0], 3).copy()\n\n    # Use numpy to scale all values by the brightness.\n    pixels *= cop_node.evalParm(\"bright\")\n\n    # Store the contents of the numpy array back into the pixel data.\n    cop_node.setPixelsOfCookingPlaneFromString(pixels.data)\n"], "extent": [14630, 15785]}]}, {"level": 2, "id": "using_cpp", "container": true, "type": "h", "indent": 0, "text": ["Writing Part of the COP in C++"], "extent": [15785, 15835], "body": [{"type": "para", "indent": 0, "text": ["Houdini\u2019s ", {"scheme": null, "value": "extendingwithcpp", "type": "link", "text": ["inlinecpp"], "fullpath": "/hom/extendingwithcpp.html"}, " module lets you easily write a portion\nof your COP in C++."], "extent": [15835, 15935]}, {"type": "para", "indent": 0, "text": ["If you construct an ", {"type": "code", "text": ["array.array"]}, " object containing the image data from an\ninput plane, you can pass the address of the array\u2019s underlying buffer into a\nC++ function and modify the contents of the array with C++ code.  The\n", {"type": "code", "text": ["buffer_info"]}, " method of array objects will return an ", {"type": "code", "text": ["(address, length)"]}, " tuple\nfor the underlying buffer, and you can pass the address into an inlinecpp C++\nfunction expecting a ", {"type": "code", "text": ["float *"]}, "."], "extent": [15935, 16348]}, {"type": "para", "indent": 0, "text": ["The following example also brightens the pixels in an image, using C++\ncode instead of the numpy module.  It assumes the COP has a float parameter\nnamed ", {"type": "code", "text": ["bright"]}, "."], "extent": [16348, 16512]}, {"lang": "python", "type": "pre", "indent": 0, "text": ["\nimport array\nimport inlinecpp\n\ndef output_planes_to_cook(cop_node):\n    return (\"C\",)\n\ndef required_input_planes(cop_node, output_plane):\n    if output_plane == \"C\":\n        return (\"0\", \"C\")\n    return ()\n\ndef cook(cop_node, plane, resolution):\n    input = cop_node.inputs()[0]\n\n    if resolution != (input.xRes(), input.yRes()):\n        # Houdini may request to cook the COP node at resolutions other\n        # than the input node's resolution.  For example, Houdini may\n        # request a lower resolution for a preview image of the COP node data.\n        # We currently cannot create a preview image so do nothing and just\n        # return.\n        return\n\n    color_pixels = array.array(\"f\", input.allPixelsAsString(plane))\n\n    cpp_lib = inlinecpp.createLibrary(\"py_brighten_cop\", function_sources=[\"\"\"\n    void brighten(float *color_pixels, int num_pixels, float amount)\n    {\n        for (int i=0; i<num_pixels; ++i)\n        {\n            color_pixels[0] *= amount;\n            color_pixels[1] *= amount;\n            color_pixels[2] *= amount;\n            color_pixels += 3;\n        }\n    }\n    \"\"\"])\n    cpp_lib.brighten(\n        color_pixels.buffer_info()[0], resolution[0] * resolution[1],\n        cop_node.evalParm(\"bright\"))\n\n    cop_node.setPixelsOfCookingPlaneFromString(color_pixels)\n"], "extent": [16512, 17830]}, {"type": "para", "indent": 0, "text": ["To get the address of the data of a ", {"type": "code", "text": ["numpy"]}, " array, simply call ", {"type": "code", "text": [".ctypes.data"]}, "\non the ", {"type": "code", "text": ["numpy"]}, " array.  To use ", {"type": "code", "text": ["numpy"]}, " instead of the ", {"type": "code", "text": ["array"]}, " module in the above\nexample, create the ", {"type": "code", "text": ["numpy"]}, " array with:"], "extent": [17830, 18031]}, {"lang": "python", "type": "pre", "indent": 0, "text": ["\ncolor_pixels = numpy.array(input.allPixelsAsString(\"C\", dtype=numpy.float32))\n"], "extent": [18031, 18126]}, {"type": "para", "indent": 0, "text": ["and call the C++ function with:"], "extent": [18126, 18160]}, {"lang": "python", "type": "pre", "indent": 0, "text": ["\ncpp_lib.brighten(color_pixels.ctypes.data, cop_node.evalParm(\"bright\"),\n    resolution[0] * resolution[1])\n"], "extent": [18160, 18284]}]}, {"level": 2, "id": "non_interleaved_data", "container": true, "type": "h", "indent": 0, "text": ["Accessing Non-Interleaved Pixel Data"], "extent": [18284, 18351], "body": [{"type": "para", "indent": 0, "text": ["Note that the examples presented here use interleaved data (the color data is\nstored as a sequence of ", {"type": "code", "text": ["RGBRGBRGB..."]}, ").  However some algorithms are easier\nto write using non-interleaved data (", {"type": "code", "text": ["RRR..."]}, ", ", {"type": "code", "text": ["GGG..."]}, ", ", {"type": "code", "text": ["BBB..."]}, "), and it\nis possible to ask the input cop2 for data in this format and to set the cooked\ndata using this format."], "extent": [18351, 18687]}, {"type": "para", "indent": 0, "text": ["The following example brightens the pixels of the input plane by operating on\none component at a time:"], "extent": [18687, 18791]}, {"lang": "python", "type": "pre", "indent": 0, "text": ["\nimport array\nimport inlinecpp\n\ndef output_planes_to_cook(cop_node):\n    return (\"C\",)\n\ndef required_input_planes(cop_node, output_plane):\n    if output_plane == \"C\":\n        return (\"0\", \"C\")\n    return ()\n\ndef cook(cop_node, plane, resolution):\n    input = cop_node.inputs()[0]\n\n    if resolution != (input.xRes(), input.yRes()):\n        # Houdini may request to cook the COP node at resolutions other\n        # than the input node's resolution.  For example, Houdini may\n        # request a lower resolution for a preview image of the COP node data.\n        # We currently cannot create a preview image so do nothing and just\n        # return.\n        return\n\n    component_values_dict = dict(\n        (component, array.array(\n            \"f\", input.allPixelsAsString(plane, component)))\n        for component in input.components(plane))\n\n    cpp_lib = inlinecpp.createLibrary(\"py_brighten_cop\", function_sources=[\"\"\"\n    void brighten(float *component_values, int num_pixels, float amount)\n    {\n        for (int i=0; i<num_pixels; ++i)\n            component_values[i] *= amount;\n    }\n    \"\"\"])\n\n    for component, component_values in component_values_dict.items():\n        cpp_lib.brighten(\n            component_values.buffer_info()[0], resolution[0] * resolution[1],\n            cop_node.evalParm(\"bright\"))\n        cop_node.setPixelsOfCookingPlaneFromString(component_values, component)\n"], "extent": [18791, 20203]}]}, {"level": 2, "id": "different_image_depths", "container": true, "type": "h", "indent": 0, "text": ["Working With Different Image Depths"], "extent": [20203, 20271], "body": [{"type": "para", "indent": 0, "text": ["The following simple example COP converts all input image planes to the\nformat specified in a menu parameter.  It assumes the menu parameter is\nnamed ", {"type": "q", "text": ["depth"]}, " and that it has the values ", {"type": "q", "text": ["Int8"]}, ", ", {"type": "q", "text": ["Int16"]}, ", ", {"type": "q", "text": ["Int32"]}, ", ", {"type": "q", "text": ["Float16"]}, ",\nor ", {"type": "q", "text": ["Float32"]}, ".  (Note that Houdini already provides a convert COP to convert\nthe image depth.)"], "extent": [20271, 20589]}, {"lang": "python", "type": "pre", "indent": 0, "text": ["\nimport inlinecpp\n\ndef output_planes_to_cook(cop_node):\n    return cop_node.inputs()[0].planes()\n\ndef required_input_planes(cop_node, output_plane):\n    return (\"0\", output_plane)\n\ndef depth(cop_node, plane):\n    return getattr(hou.imageDepth, cop_node.parm(\"depth\").evalAsString())\n\ndef cook(cop_node, plane, resolution):\n    # If we don't specify a particular depth when calling allPixelsAsString,\n    # it will convert the input plane depth into the depth of the cooking\n    # plane (which is determined by the return value from the depth function\n    # above).\n    input = cop_node.inputs()[0]\n\n    if resolution != (input.xRes(), input.yRes()):\n        # Houdini may request to cook the COP node at resolutions other\n        # than the input node's resolution.  For example, Houdini may\n        # request a lower resolution for a preview image of the COP node data.\n        # We currently cannot create a preview image so do nothing and just\n        # return.\n        return\n\n    pixels = input.allPixelsAsString(plane)\n    cop_node.setPixelsOfCookingPlaneFromString(pixels)\n"], "extent": [20589, 21685]}, {"type": "para", "indent": 0, "text": ["The following example illustrates how to preserve the depth of input planes.\nEach input plane is converted to 32-bit float point data while the Python COP\nprocesses it, and the result is converted back into the depth of the input\nplane."], "extent": [21685, 21924]}, {"lang": "python", "type": "pre", "indent": 0, "text": ["\nimport numpy\n\ndef input_of(cop_node):\n    return cop_node.inputs()[0]\n\ndef output_planes_to_cook(cop_node):\n    input_planes = input_of(cop_node).planes()\n    return [plane for plane in cop_node.evalParm(\"planes\").split()\n        if plane in input_planes]\n\ndef required_input_planes(cop_node, output_plane):\n    return (\"0\", output_plane)\n\ndef depth(cop_node, plane):\n    return input_of(cop_node).depth(plane)\n\ndef cook(cop_node, plane, resolution):\n    input = input_of(cop_node)\n\n    if resolution != (input.xRes(), input.yRes()):\n        # Houdini may request to cook the COP node at resolutions other\n        # than the input node's resolution.  For example, Houdini may\n        # request a lower resolution for a preview image of the COP node data.\n        # We currently cannot create a preview image so do nothing and just\n        # return.\n        return\n\n    pixels = numpy.frombuffer(\n        input.allPixelsAsString(plane, depth=hou.imageDepth.Float32),\n        dtype=numpy.float32)\n\n    # Perform some operation here to modify the contents of pixels.\n\n    cop_node.setPixelsOfCookingPlaneFromString(\n        pixels, depth=hou.imageDepth.Float32)\n"], "extent": [21924, 23100]}, {"type": "para", "indent": 0, "text": ["The following table lists the array format specifiers corresponding to\nthe different image depths supported in COPs:"], "extent": [23100, 23219]}, {"type": "table", "thead": [{"type": "row", "body": [{"type": "cell", "indent": 0, "text": ["Houdini enum value "], "role": "th", "extent": [23219, 23241], "container": true}, {"type": "cell", "indent": 8, "text": ["array module format string "], "role": "th", "extent": [23241, 23279], "container": true}, {"type": "cell", "indent": 16, "text": [{"type": "code", "text": ["numpy"]}, " module format constant "], "role": "th", "extent": [23279, 23329], "container": true}, {"type": "cell", "indent": 24, "text": [{"type": "code", "text": ["numpy"]}, " module format string "], "role": "th", "extent": [23329, 23385]}], "divider": false}], "body": [{"type": "row", "body": [{"type": "cell", "indent": 0, "text": [{"scheme": "Hom", "value": "/hom/hou/imageDepth#Int8", "type": "link", "text": "", "fallback_text": "hou.imageDepth.Int8", "fullpath": "/hom/hou/imageDepth.html#Int8", "fragment": "#Int8"}, " "], "role": "td", "extent": [23385, 23414], "container": true}, {"type": "cell", "indent": 8, "text": [{"type": "code", "text": ["\"B\""]}, " "], "role": "td", "extent": [23414, 23430], "container": true}, {"type": "cell", "indent": 16, "text": [{"type": "code", "text": ["numpy.uint8"]}, " "], "role": "td", "extent": [23430, 23462], "container": true}, {"type": "cell", "role": "td", "body": [{"type": "para", "indent": 24, "text": [{"type": "code", "text": ["\"u1\""]}], "extent": [23462, 23494]}]}], "divider": false}, {"type": "row", "body": [{"type": "cell", "indent": 0, "text": [{"scheme": "Hom", "value": "/hom/hou/imageDepth#Int16", "type": "link", "text": "", "fallback_text": "hou.imageDepth.Int16", "fullpath": "/hom/hou/imageDepth.html#Int16", "fragment": "#Int16"}, " "], "role": "td", "extent": [23494, 23523], "container": true}, {"type": "cell", "indent": 8, "text": [{"type": "code", "text": ["\"H\""]}, " "], "role": "td", "extent": [23523, 23539], "container": true}, {"type": "cell", "indent": 16, "text": [{"type": "code", "text": ["numpy.uint16"]}, " "], "role": "td", "extent": [23539, 23572], "container": true}, {"type": "cell", "role": "td", "body": [{"type": "para", "indent": 24, "text": [{"type": "code", "text": ["\"u2\""]}], "extent": [23572, 23604]}]}], "divider": false}, {"type": "row", "body": [{"type": "cell", "indent": 0, "text": [{"scheme": "Hom", "value": "/hom/hou/imageDepth#Int32", "type": "link", "text": "", "fallback_text": "hou.imageDepth.Int32", "fullpath": "/hom/hou/imageDepth.html#Int32", "fragment": "#Int32"}, " "], "role": "td", "extent": [23604, 23633], "container": true}, {"type": "cell", "indent": 8, "text": [{"type": "code", "text": ["\"I\""]}, " "], "role": "td", "extent": [23633, 23649], "container": true}, {"type": "cell", "indent": 16, "text": [{"type": "code", "text": ["numpy.uint32"]}, " "], "role": "td", "extent": [23649, 23682], "container": true}, {"type": "cell", "role": "td", "body": [{"type": "para", "indent": 24, "text": [{"type": "code", "text": ["\"u4\""]}], "extent": [23682, 23714]}]}], "divider": false}, {"type": "row", "body": [{"type": "cell", "indent": 0, "text": [{"scheme": "Hom", "value": "/hom/hou/imageDepth#Float16", "type": "link", "text": "", "fallback_text": "hou.imageDepth.Float16", "fullpath": "/hom/hou/imageDepth.html#Float16", "fragment": "#Float16"}, " "], "role": "td", "extent": [23714, 23745], "container": true}, {"type": "cell", "indent": 8, "text": [{"type": "em", "text": ["NA"]}, " "], "role": "td", "extent": [23745, 23760], "container": true}, {"type": "cell", "indent": 16, "text": [{"type": "code", "text": ["numpy.float16"]}, " "], "role": "td", "extent": [23760, 23794], "container": true}, {"type": "cell", "role": "td", "body": [{"type": "para", "indent": 24, "text": [{"type": "code", "text": ["\"f2\""]}, " (numpy 1.5.1+)"], "extent": [23794, 23841]}]}], "divider": false}, {"type": "row", "body": [{"type": "cell", "indent": 0, "text": [{"scheme": "Hom", "value": "/hom/hou/imageDepth#Float32", "type": "link", "text": "", "fallback_text": "hou.imageDepth.Float32", "fullpath": "/hom/hou/imageDepth.html#Float32", "fragment": "#Float32"}, " "], "role": "td", "extent": [23841, 23872], "container": true}, {"type": "cell", "indent": 8, "text": [{"type": "code", "text": ["\"f\""]}, " "], "role": "td", "extent": [23872, 23888], "container": true}, {"type": "cell", "indent": 16, "text": [{"type": "code", "text": ["numpy.float32"]}, " "], "role": "td", "extent": [23888, 23922], "container": true}, {"type": "cell", "role": "td", "body": [{"type": "para", "indent": 24, "text": [{"type": "code", "text": ["\"f4\""]}], "extent": [23922, 23954]}]}], "divider": false}]}, {"type": "para", "indent": 0, "text": ["The following example illustrates how to create a ", {"type": "code", "text": ["numpy"]}, " array of the input\nplane in its native format, for manipulation with ", {"type": "code", "text": ["numpy"]}, ":"], "extent": [23954, 24091]}, {"lang": "python", "type": "pre", "indent": 0, "text": ["\nimport numpy\n\ndef input_of(cop_node):\n    return cop_node.inputs()[0]\n\ndef output_planes_to_cook(cop_node):\n    input_planes = input_of(cop_node).planes()\n    return [plane for plane in cop_node.evalParm(\"planes\").split()\n        if plane in input_planes]\n\ndef required_input_planes(cop_node, output_plane):\n    return (\"0\", output_plane)\n\ndef depth(cop_node, plane):\n    return input_of(cop_node).depth(plane)\n\ndepths_to_numpy_types = {\n    hou.imageDepth.Int8: numpy.uint8,\n    hou.imageDepth.Int16: numpy.uint16,\n    hou.imageDepth.Int32: numpy.uint32,\n    hou.imageDepth.Float16: numpy.float16,\n    hou.imageDepth.Float32: numpy.float32\n}\n\ndef cook(cop_node, plane, resolution):\n    input = input_of(cop_node)\n\n    if resolution != (input.xRes(), input.yRes()):\n        # Houdini may request to cook the COP node at resolutions other\n        # than the input node's resolution.  For example, Houdini may\n        # request a lower resolution for a preview image of the COP node data.\n        # We currently cannot create a preview image so do nothing and just\n        # return.\n        return\n\n    pixels = numpy.frombuffer(\n        input.allPixelsAsString(plane),\n        dtype=depths_to_numpy_types[input.depth(plane)]).copy()\n\n    # Perform some operation here to modify the contents of pixels.\n\n    cop_node.setPixelsOfCookingPlaneFromString(pixels)\n"], "extent": [24091, 25465]}]}, {"level": 2, "id": "errors_and_warnings", "container": true, "type": "h", "indent": 0, "text": ["COP Errors and Warnings"], "extent": [25465, 25518], "body": [{"type": "para", "indent": 0, "text": ["If your Python COP node generates an exception, the node will turn red with an\nerror and you can view the stack trace of the error by middle-clicking on it."], "extent": [25518, 25677]}, {"type": "para", "indent": 0, "text": ["If you would like to generate an error message to the user that doesn\u2019t contain\na Python stack trace, raise a ", {"scheme": "Hom", "value": "/hom/hou/NodeError", "type": "link", "text": "", "fallback_text": "hou.NodeError", "fullpath": "/hom/hou/NodeError.html"}, " exception.  For example,\nrunning"], "extent": [25677, 25841]}, {"lang": "python", "type": "pre", "indent": 0, "text": ["\nraise hou.NodeError(\"Invalid parameter settings\")\n"], "extent": [25841, 25908]}, {"type": "para", "indent": 0, "text": ["will turn the node red with an error message of ", {"type": "code", "text": ["\"Invalid parameter settings\""]}, ".\nSimilarly, you can add node warnings by raising instances of\n", {"scheme": "Hom", "value": "/hom/hou/NodeWarning", "type": "link", "text": "", "fallback_text": "hou.NodeWarning", "fullpath": "/hom/hou/NodeWarning.html"}, "."], "extent": [25908, 26074]}]}, {"level": 2, "id": "special_function_names", "container": true, "type": "h", "indent": 0, "text": ["Special Function Names Used by COPs"], "extent": [26074, 26141], "body": [{"type": "para", "indent": 0, "text": ["For reference, here are the functions with special meaning:"], "extent": [26141, 26203]}, {"type": "bullet_group", "body": [{"blevel": 2, "type": "bullet", "indent": 0, "text": [{"type": "code", "text": ["output_planes_to_cook(cop_node)"]}], "extent": [26203, 26239]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"type": "code", "text": ["required_input_planes(cop_node, output_plane)"]}], "extent": [26239, 26289]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"type": "code", "text": ["cook(cop_node, plane, resolution)"]}], "extent": [26289, 26327]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"type": "code", "text": ["remap_frame(cop_node, frame)"]}], "extent": [26327, 26360]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"type": "code", "text": ["resolution(cop_node)"]}], "extent": [26360, 26385]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"type": "code", "text": ["output_planes_to_cook(cop_node)"]}], "extent": [26385, 26421]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"type": "code", "text": ["depth(cop_node, plane)"]}], "extent": [26421, 26448]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"type": "code", "text": ["frame_range(cop_node)"]}], "extent": [26448, 26475]}], "container": true}]}], "title": ["Define a compositing node (COP) using Python"]}