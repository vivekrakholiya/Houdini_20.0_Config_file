{"type": "root", "attrs": {"icon": "/nodes/sop/gsop--gaussian_splats_generate_training_data-1.0/render_region.svg", "type": "node", "context": "sop", "internal": "gaussian_splats_generate_training_data", "version": "1.0", "namespace": "gsop"}, "body": [{"level": 0, "type": "title", "indent": 0, "text": ["Gaussian Splats Generate Training Data"], "extent": [0, 43]}, {"type": "summary", "indent": 0, "text": ["Generate synthetic data suitable for training gaussian splat models."], "extent": [78, 154]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 0, "text": ["Overview"], "extent": [154, 169], "body": [{"type": "para", "indent": 0, "text": ["You can create gaussian splat models using synthetic data (CGI). This allows for the compression and rendering optimization of high-fidelity graphics with view-dependent effects."], "extent": [169, 349]}, {"type": "para", "indent": 0, "text": [{"scheme": "Image", "value": "/nodes/sop/gsop--gaussian_splats_generate_training_data-1.0/generate_training_data_example.png", "type": "img", "text": ""}, "\n", {"type": "em", "text": ["Example of a volumetric cloud converted to gaussian splats (rendered in Unity)."]}], "extent": [349, 483]}, {"type": "para", "indent": 0, "text": ["Use this node to render the viewport and generate images.bin, cameras.bin, and points3D.ply/.bin files (required for gaussian splat training)."], "extent": [483, 627]}, {"type": "para", "indent": 0, "text": ["When the second input ", {"type": "code", "text": ["Packed Cameras"]}, " is not provided, cameras can be procedurally generated using inflation and relaxation techniques, based on the input ", {"type": "code", "text": ["Geometry to Capture"]}, ".\nThis is effective for generating gaussian splat models of a singular object (opposed to an environment)."], "extent": [627, 912]}, {"type": "para", "indent": 0, "text": ["Inflation and relaxation is not suitable to generate sufficient camera coverage in many instances. Therefore, you can also provide your own ", {"type": "code", "text": ["Packed Cameras"]}, "."], "extent": [912, 1071]}]}, {"level": 1, "id": "inputs", "container": true, "type": "inputs_section", "indent": 0, "role": "section", "extent": [1071, 1079], "body": [{"type": "dt_group", "body": [{"type": "dt", "indent": 0, "text": ["Geometry to Capture"], "extent": [1079, 1101], "body": [{"type": "para", "indent": 4, "text": ["The polygonal geometry you would like to generate camera coverage for."], "extent": [1101, 1177]}], "container": true}, {"type": "dt", "indent": 0, "text": ["Packed Cameras"], "extent": [1177, 1193], "body": [{"type": "para", "indent": 4, "text": ["Geometry with point attributes describing camera transforms. Each point should represent one camera."], "extent": [1193, 1303]}, {"type": "para", "indent": 4, "text": ["The following point attributes can be used:"], "extent": [1303, 1351]}, {"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": ["N (the forward/aim vector of the camera)"], "extent": [1351, 1398]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["orient (the quaternion rotation of the camera)"], "extent": [1398, 1456]}], "container": true}], "container": true}, {"type": "dt", "indent": 0, "text": ["Initialization Points"], "extent": [1456, 1479], "body": [{"type": "para", "indent": 4, "text": ["The points to use for gaussian splat training initialization. \n    When using real-world data, initialization points are generated using structure from motion (SfM), generally derived from COLMAP. \n    However, when generating synthetic gaussian splat models, we can source our initialization points in a number of ways. "], "extent": [1479, 1810]}, {"type": "tip_group", "body": [{"type": "tip", "indent": 4, "role": "item", "extent": [1810, 1819], "body": [{"type": "para", "indent": 8, "text": ["Use a combination of Scatter and Points from Volume to generate a suitable initialization set. \n        50-100k points work well for object-centric scans. \n        If you intend to deform your trained splat models, a surface-based initialization set may work best."], "extent": [1819, 2101]}], "container": true}], "container": true, "role": "item_group"}, {"type": "para", "indent": 4, "text": ["Color (Cd) is not required, but may produce better trained results if provided. "], "extent": [2101, 2191]}], "container": true}], "container": true}], "text": "Inputs"}, {"level": 1, "id": "outputs", "container": true, "type": "outputs_section", "indent": 0, "role": "section", "extent": [2191, 2200], "body": [{"type": "dt_group", "body": [{"type": "dt", "indent": 0, "text": ["Packed Cameras"], "extent": [2200, 2217], "body": [{"type": "para", "indent": 4, "text": ["Point geometry describing a set of cameras. Each point represents one camera, containing the following attributes:"], "extent": [2217, 2341]}, {"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": ["N"], "extent": [2341, 2349]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["forward (note: forward is the inverse of N)"], "extent": [2349, 2399]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["up"], "extent": [2399, 2408]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["orient"], "extent": [2408, 2421]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["xform (matrix4)"], "extent": [2421, 2448]}], "container": true}], "container": true}], "container": true}], "text": "Outputs"}, {"level": 1, "id": "parameters", "container": true, "type": "parameters_section", "indent": 0, "role": "section", "extent": [2448, 2460], "body": [{"level": 2, "id": null, "container": true, "type": "h", "indent": 0, "text": ["Camera Generation Settings"], "extent": [2460, 2494], "body": [{"level": 3, "id": null, "container": true, "type": "h", "indent": 0, "text": ["Mesh Settings"], "extent": [2494, 2517], "body": [{"type": "para", "indent": 0, "text": ["Inflation is based on VDB and the Peak SOP. "], "extent": [2517, 2564]}, {"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Voxel Size"], "extent": [2564, 2576], "body": [{"type": "para", "indent": 4, "text": ["The size of the voxel for internal VDB construction. "], "extent": [2596, 2655]}], "container": true, "attrs": {"id": "voxelsize"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Dilation Amount"], "extent": [2655, 2672], "body": [{"type": "para", "indent": 4, "text": ["The amount (in voxels) to dilate the internally created VDB volume. "], "extent": [2702, 2780]}], "container": true, "attrs": {"id": "dilation_amount"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Remesh Target Size"], "extent": [2780, 2804], "body": [{"type": "para", "indent": 4, "text": ["The goal distance between cameras. Determines the number of cameras generated\n    (Target edge length for the internal Remesh SOP.)"], "extent": [2837, 2978]}, {"type": "tip_group", "body": [{"type": "tip", "indent": 4, "role": "item", "extent": [2978, 2987], "body": [{"type": "para", "indent": 8, "text": ["Aim for 300-500 cameras for the best ratio of quality and processing time."], "extent": [2987, 3071]}], "container": true}], "container": true, "role": "item_group"}], "container": true, "attrs": {"id": "remesh_target_size"}, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 3, "id": null, "container": true, "type": "h", "indent": 0, "text": ["Peak Settings"], "extent": [3071, 3093], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Pre-smooth N Strength"], "extent": [3093, 3117], "body": [{"type": "para", "indent": 4, "text": ["The amount to smooth N (normals) before further inflating the mesh. This helps produce evenly distributed cameras."], "extent": [3153, 3277]}], "container": true, "attrs": {"id": "pre_smooth_n_strength"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Peak Distance"], "extent": [3277, 3292], "body": [{"type": "para", "indent": 4, "text": ["The amount to inflate the mesh by its normals. Useful to push the cameras away from the target capture geometry."], "extent": [3320, 3442]}], "container": true, "attrs": {"id": "peak_distance"}, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 3, "id": null, "container": true, "type": "h", "indent": 0, "text": ["Aim Settings"], "extent": [3442, 3463], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Aim at Center"], "extent": [3463, 3479], "body": [{"type": "para", "indent": 4, "text": ["Use this toggle to force each camera to aim at the center of the ", {"type": "code", "text": ["Geometry to Capture"]}, "."], "extent": [3507, 3604]}], "container": true, "attrs": {"id": "aim_at_center"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Smooth N Strength"], "extent": [3604, 3623], "body": [{"type": "para", "indent": 4, "text": ["The amount to smooth the camera aim vector (N). \n    A lower value will generate more geometry-aware camera angles, but could lead to under-sampling. \n    A higher value will produce more evenly distributed camera aim vectors, but may reduce coverage in some areas."], "extent": [3655, 3930]}], "container": true, "attrs": {"id": "smooth_n_strength"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Remove Tilt"], "extent": [3930, 3943], "body": [{"type": "para", "indent": 4, "text": ["The amount to remove the tilt of each camera. A value of 1 produces cameras angles that are strictly horizontal. "], "extent": [3969, 4089]}], "container": true, "attrs": {"id": "remove_tilt"}, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 3, "id": null, "container": true, "type": "h", "indent": 0, "text": ["General Settings"], "extent": [4089, 4114], "body": [{"type": "para", "indent": 4, "text": ["The amount to relax camera positions, after all other operations. This helps produce evenly distributed cameras."], "extent": [4145, 4263]}], "attrs": {"id": "relax_iterations"}}, {"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Sort Cameras"], "extent": [4263, 4277], "body": [{"type": "para", "indent": 4, "text": ["Use this to simulate a camera animation trajectory which rotates around the ", {"type": "code", "text": ["Geometry to Capture"]}, " in clockwise order, starting from the bottom and ending at the top.\n    Useful to temporally analyze overall camera coverage (as if you had recorded video for a physical scan)."], "extent": [4304, 4584]}], "container": true, "attrs": {"id": "sort_cameras"}, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 0, "text": ["Aim Settings (", {"type": "code", "text": ["Packed Cameras"]}, " input2)"], "extent": [4584, 4629], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Aim Mode"], "extent": [4629, 4639], "body": [{"type": "para", "indent": 4, "text": ["Camera aim strategy."], "extent": [4658, 4688]}, {"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": ["Use Orient: use the quaternion orient attribute to specify camera rotation."], "extent": [4688, 4770]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["Use Normal: use the N attribute to specify the aim vector. The up vector is computed automatically using cross product with the world up vector. "], "extent": [4770, 4922]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["Aim at Center: use the center of the ", {"type": "code", "text": ["Geometry to Capture"]}, " to determine camera aim. Only the P point attribute is required."], "extent": [4922, 5057]}], "container": true}], "container": true, "attrs": {"id": "aim_mode"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Remove Tilt"], "extent": [5057, 5070], "body": [{"type": "para", "indent": 4, "text": ["The amount to remove the tilt of each camera. A value of 1 produces cameras angles that are strictly horizontal. "], "extent": [5103, 5226]}], "container": true, "attrs": {"id": "remove_tilt_packed"}, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 0, "text": ["Camera Generation Settings"], "extent": [5226, 5259], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Preview Camera Geometry"], "extent": [5259, 5285], "body": [{"type": "para", "indent": 4, "text": ["Enable this to preview camera geometry for each camera point."], "extent": [5318, 5389]}], "container": true, "attrs": {"id": "preview_camera_geo"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Camera Geometry Size"], "extent": [5389, 5411], "body": [{"type": "para", "indent": 4, "text": ["The scale for all camera geometry."], "extent": [5447, 5491]}], "container": true, "attrs": {"id": "camera_geometry_scale"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Preview Camera Animation"], "extent": [5491, 5517], "body": [{"type": "para", "indent": 4, "text": ["If this is enabled, AND a valid camera_path is provided, you can scrub/play the timeline to preview/render the camera trajectory.\n    This is required if you intend to render the viewport for training validation."], "extent": [5556, 5778]}, {"type": "warning_group", "body": [{"type": "warning", "indent": 4, "text": [" "], "role": "item", "extent": [5778, 5792], "body": [{"type": "para", "indent": 8, "text": ["Disable this when using ", {"type": "code", "text": ["visualize_camera_coverage"]}, " for improved performance."], "extent": [5792, 5883]}], "container": true}], "container": true, "role": "item_group"}], "container": true, "attrs": {"id": "preview_camera_animation"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Create Camera"], "extent": [5883, 5898], "body": [{"type": "para", "indent": 4, "text": ["Press this convenience button to create a new camera and automatically set the ", {"type": "code", "text": ["camera_path"]}, " parameter. "], "extent": [5927, 6041]}], "container": true, "attrs": {"id": "create_camera:"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Camera Path"], "extent": [6041, 6054], "body": [{"type": "para", "indent": 4, "text": ["The camera operator path for which to look through/preview camera animation and render the viewport.\n    This is also used to compute the cumulative camera coverage of your ", {"type": "code", "text": ["Geometry to Capture"]}, "."], "extent": [6080, 6281]}], "container": true, "attrs": {"id": "camera_path"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Focal Length"], "extent": [6281, 6296], "body": [{"type": "para", "indent": 4, "text": ["Sets the focal length of the camera assigned to ", {"type": "code", "text": ["camera_path"]}, ". This will affect the camera coverage visualization."], "extent": [6323, 6447]}, {"type": "tip_group", "body": [{"type": "tip", "indent": 4, "role": "item", "extent": [6447, 6456], "body": [{"type": "para", "indent": 9, "text": ["Recommended value for best detail to coverage ratio: 25-35."], "extent": [6456, 6530]}], "container": true}], "container": true, "role": "item_group"}], "container": true, "attrs": {"id": "focal_length"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Look Through Camera"], "extent": [6530, 6551], "body": [{"type": "para", "indent": 4, "text": ["Press this convenience button to quickly look through and lock the camera (specified in ", {"type": "code", "text": ["camera_path"]}, ") to the active viewport. \n    This happens automatically when using the ", {"type": "code", "text": ["render_viewport"]}, " button."], "extent": [6576, 6781]}], "container": true, "attrs": {"id": "use_camera"}, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 0, "text": ["Date Generation Settings"], "extent": [6781, 6813], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Data Directory"], "extent": [6813, 6830], "body": [{"type": "para", "indent": 4, "text": ["The directory to save viewport render images, camera.bin, images.bin, and points3D.ply. \n    This should be in the root data directory of the gaussian splat training repo location (e.g., ../gaussian-splatting-Windows/data/{})."], "extent": [6859, 7095]}], "container": true, "attrs": {"id": "data_directory"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Image Prefix"], "extent": [7095, 7109], "body": [{"type": "para", "indent": 4, "text": ["The image prefix for viewport renders. "], "extent": [7136, 7185]}], "container": true, "attrs": {"id": "image_prefix"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Image Type"], "extent": [7185, 7197], "body": [{"type": "para", "indent": 4, "text": ["The file extension used for the viewport or flipbook renders."], "extent": [7222, 7297]}, {"type": "tip_group", "body": [{"type": "tip", "indent": 4, "role": "item", "extent": [7297, 7306], "body": [{"type": "para", "indent": 8, "text": ["If you'd like to used Alpha masked images for training very clean models in Postshot or NerfStudio/Gsplat, prefer *.png."], "extent": [7306, 7444]}], "container": true}], "container": true, "role": "item_group"}, {"type": "note_group", "body": [{"type": "note", "indent": 4, "role": "item", "extent": [7444, 7454], "body": [{"type": "para", "indent": 8, "text": ["After changing this extension, you should re-render your scene and ", {"type": "code", "text": ["save training data"]}, ". This ensures the data types match across files."], "extent": [7454, 7604]}], "container": true}], "container": true, "role": "item_group"}], "container": true, "attrs": {"id": "image_type"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Render Viewport"], "extent": [7604, 7621], "body": [{"type": "para", "indent": 4, "text": ["Press this button to render the viewport for rapid training validation loops. \n    Images are saved in {data_directory}/images."], "extent": [7651, 7788]}, {"type": "tip_group", "body": [{"type": "tip", "indent": 4, "role": "item", "extent": [7788, 7797], "body": [{"type": "para", "indent": 8, "text": ["for best results, disable the grid, and ensure your current viewport has all visualizers disabled. "], "extent": [7797, 7910]}], "container": true}], "container": true, "role": "item_group"}, {"type": "note_group", "body": [{"type": "note", "indent": 4, "role": "item", "extent": [7910, 7920], "body": [{"type": "para", "indent": 8, "text": ["The viewport resolution will determine the image resolution. As an alternative, you can render the scene using ", {"scheme": null, "value": "https://www.sidefx.com/docs/houdini/render/flipbook.html", "type": "link", "text": ["Flipbook"], "exists": true}, ".\n        This allows better control over image and color settings."], "extent": [7920, 8179]}], "container": true}], "container": true, "role": "item_group"}, {"type": "tip_group", "body": [{"type": "tip", "indent": 4, "role": "item", "extent": [8179, 8188], "body": [{"type": "para", "indent": 8, "text": ["A resolution of ~720\u00d7720 produces quality results and rapid training times (~1 minute for 7k iterations on a 3800 using 300 images)."], "extent": [8188, 8338]}], "container": true}], "container": true, "role": "item_group"}], "container": true, "attrs": {"id": "render_viewport"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Override Initialization Point Color"], "extent": [8338, 8375], "body": [{"type": "para", "indent": 4, "text": ["Enable this to set or override the color of initialization points. \n    Color is optimized during gaussian splat training, and is therefore not strictly required. "], "extent": [8425, 8598]}, {"type": "tip_group", "body": [{"type": "tip", "indent": 4, "role": "item", "extent": [8598, 8607], "body": [{"type": "para", "indent": 8, "text": ["Accurately colored points are preferable. However, white points will often reconstruct accurately."], "extent": [8607, 8715]}], "container": true}], "container": true, "role": "item_group"}], "container": true, "attrs": {"id": "override_initialization_point_color"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Override Camera Resolution"], "extent": [8715, 8743], "body": [{"type": "para", "indent": 4, "text": ["Enable this to explicitly set the camera/image resolution of your final renders (i.e., not the viewport renders)."], "extent": [8784, 8907]}, {"type": "note_group", "body": [{"type": "note", "indent": 4, "role": "item", "extent": [8907, 8917], "body": [{"type": "para", "indent": 8, "text": ["This will only affect data written to cameras.bin. "], "extent": [8917, 8986]}], "container": true}], "container": true, "role": "item_group"}, {"type": "warning_group", "body": [{"type": "warning", "indent": 4, "role": "item", "extent": [8986, 8999], "body": [{"type": "para", "indent": 8, "text": ["Disable this when using viewport renders!"], "extent": [8999, 9058]}], "container": true}], "container": true, "role": "item_group"}], "container": true, "attrs": {"id": "override_camera_resolution"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Camera Resolution"], "extent": [9058, 9077], "body": [{"type": "para", "indent": 4, "text": ["The the exact camera/image resolution (width x height) of your final renders (i.e., not the viewport renders)."], "extent": [9110, 9230]}, {"type": "tip_group", "body": [{"type": "tip", "indent": 4, "role": "item", "extent": [9230, 9239], "body": [{"type": "para", "indent": 8, "text": ["Example workflow: "], "extent": [9239, 9266]}, {"type": "ord_group", "body": [{"blevel": 10, "type": "ord", "indent": 8, "text": ["Generate or provide your cameras. "], "extent": [9266, 9311]}, {"blevel": 10, "type": "ord", "indent": 8, "text": ["Validate coverage using ", {"type": "code", "text": ["visualize_cumuluative_camera_coverage"]}, "."], "extent": [9311, 9386]}, {"blevel": 10, "type": "ord", "indent": 8, "text": ["Render the viewport."], "extent": [9386, 9417]}, {"blevel": 10, "type": "ord", "indent": 8, "text": ["Save the training data (with ", {"type": "code", "text": ["override_camera_resolution"]}, " disabled)."], "extent": [9417, 9496]}, {"blevel": 10, "type": "ord", "indent": 8, "text": ["Train your test gaussian splat model."], "extent": [9496, 9544]}, {"blevel": 10, "type": "ord", "indent": 8, "text": ["Iterate as necessary."], "extent": [9544, 9576]}, {"blevel": 10, "type": "ord", "indent": 8, "text": ["When you're happy, use your final ", {"type": "code", "text": ["Packed Cameras"]}, " to perform higher quality renders."], "extent": [9576, 9672]}, {"blevel": 10, "type": "ord", "indent": 8, "text": ["Enable ", {"type": "code", "text": ["override_camera_resolution"]}, " and set ", {"type": "code", "text": ["camera_resolution"]}, " according to your final render resolution."], "extent": [9672, 9789]}, {"blevel": 10, "type": "ord", "indent": 8, "text": ["Save training data again."], "extent": [9789, 9825]}, {"blevel": 10, "type": "ord", "indent": 8, "text": ["Train your final model."], "extent": [9825, 9868]}], "container": true}], "container": true}, {"type": "tip", "indent": 4, "role": "item", "extent": [9868, 9877], "body": [{"type": "para", "indent": 8, "text": ["There are diminishing returns at resolutions > 1600 in final trained models. Prefer smaller resolutions and more cameras for best results."], "extent": [9877, 10025]}], "container": true}], "container": true, "role": "item_group"}], "container": true, "attrs": {"id": "camera_resolution:"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Camera & Images Type"], "extent": [10025, 10047], "body": [{"type": "para", "indent": 4, "text": ["The data type you would like to export the COLMAP-formatted ", {"type": "code", "text": ["cameras"]}, " and ", {"type": "code", "text": ["images"]}, " files."], "extent": [10080, 10179]}, {"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": ["bin: COLMAP model data type. Useful for NerfStudio (Splatfacto) and Postshot."], "extent": [10179, 10263]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["txt: ASCII COLMAP model data type. Larger file size, but simpler to read and debug."], "extent": [10263, 10358]}], "container": true}, {"type": "warning_group", "body": [{"type": "warning", "indent": 4, "role": "item", "extent": [10358, 10371], "body": [{"type": "para", "indent": 8, "text": ["It is generally recommended to use the same file type for cameras, images, and points3D!"], "extent": [10371, 10477]}], "container": true}], "container": true, "role": "item_group"}], "container": true, "attrs": {"id": "camera_images_type"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Points3D Type"], "extent": [10477, 10492], "body": [{"type": "para", "indent": 4, "text": ["The data type you would like to export the initialization points as."], "extent": [10520, 10598]}, {"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": ["bin: COLMAP model data type. Useful for NerfStudio (Splatfacto) and Postshot."], "extent": [10598, 10682]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["txt: ASCII COLMAP model data type. Larger file size, but simpler to read and debug."], "extent": [10682, 10772]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["ply: Default data type used by Inria\u2019s 3DGS implementation. This format can be imported by many applications."], "extent": [10772, 10893]}], "container": true}, {"type": "warning_group", "body": [{"type": "warning", "indent": 4, "role": "item", "extent": [10893, 10906], "body": [{"type": "para", "indent": 8, "text": ["It is generally recommended to use the same file type for cameras, images, and points3D!"], "extent": [10906, 11013]}], "container": true}], "container": true, "role": "item_group"}], "container": true, "attrs": {"id": "points3D_type"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Save Training Data"], "extent": [11013, 11034], "body": [{"type": "para", "indent": 4, "text": ["Press this button to export all required (COLMAP-compatible) training data:"], "extent": [11067, 11152]}, {"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": ["{data_directory}/sparse/0/cameras.{camera_images_type}"], "extent": [11152, 11213]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["{data_directory}/sparse/0/images.{camera_images_type}"], "extent": [11213, 11278]}], "container": true}, {"type": "para", "indent": 4, "text": ["If ", {"type": "code", "text": ["Initialization Points"]}, " input is provided:"], "extent": [11278, 11333]}, {"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": ["{data_directory}/sparse/0/points3D.{points3D_type}"], "extent": [11333, 11395]}], "container": true}, {"type": "tip_group", "body": [{"type": "tip", "indent": 4, "role": "item", "extent": [11395, 11404], "body": [{"type": "para", "indent": 8, "text": ["Using this approach means you do not need to use COLMAP/SfM to generate initialization points. \n        If you do use the Gaussian Splatting ", {"type": "code", "text": ["convert.py"]}, " script, be sure to import and align your SfM point cloud (see embedded node: ", {"type": "code", "text": ["SFM_MODEL_ALIGNMENT_EXPORT"]}, "), then ", {"type": "code", "text": ["Save Training Data"]}, ". \n        This provides the most accurate camera information for training."], "extent": [11404, 11780]}], "container": true}], "container": true, "role": "item_group"}], "container": true, "attrs": {"id": "save_training_data"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Camera File"], "extent": [11780, 11793], "body": [{"type": "para", "indent": 4, "text": ["The file to save packed cameras to. "], "extent": [11819, 11865]}], "container": true, "attrs": {"id": "camera_file"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Export Packed Cameras"], "extent": [11865, 11888], "body": [{"type": "para", "indent": 4, "text": ["Press this button to save the packed cameras to disk. Useful for caching or I/O with other 3D software."], "extent": [11924, 12033]}], "container": true, "attrs": {"id": "export_packed_cameras"}, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 0, "text": ["Visualization Settings"], "extent": [12033, 12062], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Visualize Cumulative Camera Coverage"], "extent": [12062, 12101], "body": [{"type": "para", "indent": 4, "text": ["Enable this to preview the overall camera coverage metrics for the provided ", {"type": "code", "text": ["Geometry to Capture"]}, ". \n    This is useful to validate your camera configuration before training. "], "extent": [12141, 12325]}, {"type": "para", "indent": 4, "text": [{"scheme": "Image", "value": "/nodes/sop/gsop--gaussian_splats_generate_training_data-1.0/generate_training_data_coverage_visualization.png", "type": "img", "text": ""}, "\n    ", {"type": "em", "text": ["Previewing camera coverage with a range of 20-40."]}], "extent": [12325, 12456]}, {"type": "tip_group", "body": [{"type": "tip", "indent": 4, "role": "item", "extent": [12456, 12465], "body": [{"type": "para", "indent": 8, "text": ["The more cameras that see/render every part of the mesh, the better your trained results. Aim for a minimum of 10 cameras throughout your mesh."], "extent": [12465, 12626]}], "container": true}], "container": true, "role": "item_group"}, {"type": "para", "indent": 4, "text": ["Coverage is computed as follows:"], "extent": [12626, 12663]}, {"type": "ord_group", "body": [{"blevel": 6, "type": "ord", "indent": 4, "text": ["For each camera, identify points inside the view frustum. "], "extent": [12663, 12728]}, {"blevel": 6, "type": "ord", "indent": 4, "text": ["For points inside the view frustum, cast a ray to the camera, checking for intersections. If the ray does not produce a hit, the point is considered visible to the camera."], "extent": [12728, 12906]}, {"blevel": 6, "type": "ord", "indent": 4, "text": ["Accumulate the visibility metric for each point."], "extent": [12906, 12966]}], "container": true}, {"type": "warning_group", "body": [{"type": "warning", "indent": 4, "text": [" "], "role": "item", "extent": [12966, 12980], "body": [{"type": "para", "indent": 8, "text": ["Disable before rendering the viewport for improved performance!"], "extent": [12980, 13057]}], "container": true}], "container": true, "role": "item_group"}], "container": true, "attrs": {"id": "visualize_camera_coverage"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Camera Coverage Stats"], "extent": [13057, 13080], "body": [{"type": "para", "indent": 4, "text": ["A statistical display of the camera coverage (visibility) metric. Useful for analyzing the spread of coverage across the mesh. \n    For consistent results, aim for a lower standard deviation and high mean/median."], "extent": [13116, 13338]}], "container": true, "attrs": {"id": "camera_coverage_stats"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Visibility Min/Max"], "extent": [13338, 13358], "body": [{"type": "para", "indent": 4, "text": ["The minimum and maximum number of cameras for visualization. \n    Regions with coverage of 10 cameras or fewer will likely produce holes and blurry results in trained models."], "extent": [13391, 13575]}], "container": true, "attrs": {"id": "visibility_min_max"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Color Ramp"], "extent": [13575, 13587], "body": [{"type": "para", "indent": 4, "text": ["The colors used to visualize camera coverage."], "extent": [13612, 13670]}], "container": true, "attrs": {"id": "color_ramp"}, "role": "item"}], "container": true, "role": "item_group"}]}], "text": "Parameters"}, {"level": 1, "id": "related", "container": true, "type": "related_section", "indent": 0, "role": "section", "extent": [13670, 13679], "body": [{"level": 1, "id": "related", "container": true, "type": "related_section", "indent": 0, "role": "section", "extent": [3878, 3887], "body": [{"type": "para", "indent": 0, "text": ["General"], "extent": [3887, 3895]}, {"type": "bullet_group", "body": [{"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_align_by_points-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_align_by_points-1.0.html"}], "extent": [3895, 3950]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_attribute_adjust-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_attribute_adjust-1.0.html"}], "extent": [3950, 4006]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_crop-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_crop-1.0.html"}], "extent": [4006, 4050]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_dbscan-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_dbscan-1.0.html"}], "extent": [4050, 4096]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_deform-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_deform-1.0.html"}], "extent": [4096, 4142]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_evaluate_spherical_harmonics-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_evaluate_spherical_harmonics-1.0.html"}], "extent": [4142, 4210]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_export-3.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_export-3.0.html"}], "extent": [4210, 4256]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_feature_analysis-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_feature_analysis-1.0.html"}], "extent": [4256, 4312]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_from_polygons-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_from_polygons-1.0.html"}], "extent": [4312, 4365]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_generate_training_data-2.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_generate_training_data-2.0.html"}], "extent": [4365, 4427]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_hald_clut-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_hald_clut-1.0.html"}], "extent": [4427, 4476]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_import-2.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_import-2.0.html"}], "extent": [4476, 4522]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_import_cameras-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_import_cameras-1.0.html"}], "extent": [4522, 4576]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_relight_ibl-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_relight_ibl-1.0.html"}], "extent": [4576, 4627]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_source-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_source-1.0.html"}], "extent": [4627, 4673]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_transform-1.1", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_transform-1.1.html"}], "extent": [4673, 4722]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_visualize_boxes-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_visualize_boxes-1.0.html"}], "extent": [4722, 4778]}], "container": true}, {"type": "para", "indent": 0, "text": ["Coarse Meshing"], "extent": [4778, 4793]}, {"type": "bullet_group", "body": [{"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_apply_normals-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_apply_normals-1.0.html"}], "extent": [4793, 4846]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--splat_mesh_from_point_cloud-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--splat_mesh_from_point_cloud-1.0.html"}], "extent": [4846, 4897]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--splat_mesh_from_vdb-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--splat_mesh_from_vdb-1.0.html"}], "extent": [4897, 4940]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_prepare_for_vdb-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_prepare_for_vdb-1.0.html"}], "extent": [4940, 4995]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_vdb_slice-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_vdb_slice-1.0.html"}], "extent": [4995, 5044]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--VDB_from_gaussian_splats-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--VDB_from_gaussian_splats-1.0.html"}], "extent": [5044, 5093]}], "container": true}, {"type": "para", "indent": 0, "text": ["Toys"], "extent": [5093, 5098]}, {"type": "bullet_group", "body": [{"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_advect-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_advect-1.0.html"}], "extent": [5098, 5144]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_font-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_font-1.0.html"}], "extent": [5144, 5188]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/sop/gsop--gaussian_splats_jellify-1.0", "type": "link", "text": "", "fullpath": "/nodes/sop/gsop--gaussian_splats_jellify-1.0.html"}], "extent": [5188, 5234]}], "container": true}], "text": "Related"}], "text": "Related"}], "title": ["Gaussian Splats Generate Training Data"], "summary": ["Generate synthetic data suitable for training gaussian splat models."], "included": ["/nodes/sop/gsop--gaussian_splats_import-2.0"]}